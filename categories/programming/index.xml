<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Programming on</title><link>/categories/programming/</link><description>Recent content in Programming on</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Mon, 10 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="/categories/programming/index.xml" rel="self" type="application/rss+xml"/><item><title>CSPRNG 如何做到不可预测</title><link>/posts/csprng/</link><pubDate>Mon, 10 May 2021 00:00:00 +0000</pubDate><guid>/posts/csprng/</guid><description>上一篇文章 我们提到了实现伪随机数生成器 PRNG 的一种经典算法: 线性同余法. 我们也提到了线性同余法由于无法做到不可预测而不能成为密码学安全的算法, 如果对其加以改进使做到不可预测，我们就能够得到密码学安全的随机数生成器 CSPRNG. 本文我们就来看看线性同余法是如何被预测的以及 CSPRNG 是如何克服这一点的.
线性同余为什么是可预测的 线性同余的公示如下, A, C, M 是常数:
$$R_{n+1} = (A \times R_n + C) \bmod M$$1
其中
$$R_0 = (A \times seed + C) \bmod M$$
我们说过不可预测的定义:
即使给出产生序列的算法或硬件和所有以前产生的位序列, 也不可能通过计算来预测下一个随机位是什么.
应用密码学: 协议, 算法与 C 源程序》第 2 版2
线性同余的算法很简单只是一个多项式, 其常数 A, C, M 一般是不公开的, seed 一般也不会让我们知道, 但是显然我们只要知道它生成的 4 个随机数, 就能反推出 A, C, M 以及 seed, 从而整个随机序列我们都能知晓.
CSPRNG 如何做到不可预测 由上述可知线性同余的问题在于容易被反推, 所以首先我们要解决容易反推的问题, 如果做到不被反推呢?</description></item><item><title>随机数与伪随机数生成器</title><link>/posts/prng/</link><pubDate>Sun, 09 May 2021 00:00:00 +0000</pubDate><guid>/posts/prng/</guid><description>想必我们都知道随机数和伪随机数的说法, 但是未必真能说清楚他们二者的区别, 只是隐约的知道伪随机数不是真正的随机数, 但是再往深了说就说不清了. 那今天我们就来深入的研究一下二者的区别.
什么是随机数? 起笔时我才发现还真是很难给出随机数的定义, 于是我搜索了一番, 发现不仅 Google 没有答案, 连我参考的两本密码学的名著也没有明确定义. 奈何这一段的标题都写出来了, 所以我苦思了好几分钟, 认为这一定义还是比较不错的:
不确定的数.
这背后延伸的意思就是, “不被安排” “不是遵循某个规则产生”, 这个定义和英文单词 &amp;ldquo;random&amp;rdquo; 的释义有着异曲同工之妙:
“确定” 和 “不确定” 在物理世界中都是广泛存在的, 比如抛出的硬币确定会落地, 但是哪面朝上就不确定了. 但是对计算机来说, “不确定” 却是不存在的, 因为数学一定是确定的, 计算机就是数学, 计算机里的程序, 算法, 对于确定的输入, 一定会得到确定的输出. 如何让计算机输出不确定的结果? 那就是把外界的不确定作为计算机的输入.
物理世界中的不确定也就是我们所说的真随机(TRNG).
伪随机 由于真随机来自于计算机外部, 获得的代价往往较高, 而在计算机的应用场景中我们也并不总是要求随机数都有真随机那么高的不确定性, 所以这就衍生出了对伪随机的需求. 伪随机由算法产生, 设计良好的算法产生的随机序列能够以假乱真, 产生伪随机数的算法被叫做伪随机数生成器.
伪随机数生成器通常接受一个 seed 用来初始化生成器的初始状态, 后面会看到, 这个 seed 在某些情况下是必须提供的, 在另外一些情况下可以不提供, 但即使是在不需要提供的情况下, 提供 seed 仍然是较好的工程实践1.
随机的三重等级 业界特别是密码学领域将随机分为三个级别:
伪随机 (PRNG) 密码学安全的伪随机 (CSPRNG) 真随机 (TRNG) 伪随机 (PRNG) Pseudo-random number generator</description></item><item><title>对解释器与 JIT 的一点思考</title><link>/posts/jit/</link><pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate><guid>/posts/jit/</guid><description>我一直知道解释器与编译器的区别. 编译器是事先将代码编译成机器码, 然后直接送进内存让 cpu 执行, 解释器则是解释执行代码, 可能会将代码先转换成一种中间码, 但我一直有一个误区就是解释器在解释执行的时候会把源代码或者中间码转成机器码, 也直接交由 cpu 执行, 然而我错了. 解释器是不会把源代码或者中间码转换成机器码的, 源代码或者中间码是直接在解释器内部的虚拟机上执行的.
当我认识到这一点之后, 我首先想到的虚拟机怎么实现的基本操作? 比如不借助 cpu 中的 ALU (加法器), 虚拟机怎么实现加法操作? 比如 2 + 3 这个表达式, 在词法分析后得到 &amp;ldquo;2&amp;rdquo; &amp;ldquo;+&amp;rdquo; &amp;ldquo;3&amp;rdquo; 三个 token, 虚拟机可以知道这是加法, 但是它怎么知道 &amp;ldquo;2&amp;rdquo; 和 &amp;ldquo;3&amp;rdquo; 分别代表多少? 2 + 3 它要怎么计算? 这是虚拟机无法模拟的. 略加思考, 我明白了, 试想一下, 虚拟机是什么语言写的? 虚拟机又是运行在哪里?
对的, 虚拟机本质上还是一坨直接运行于 cpu 之上的机器码, 当它拿到 &amp;ldquo;2&amp;rdquo; &amp;ldquo;+&amp;rdquo; &amp;ldquo;3&amp;rdquo; 的时候, 就直接讲这道题交给 cpu 的 ALU 去完成了, 然后取得结果作为它所解释的程序的运行结果.
那么 JIT (Just in Time) 是什么呢? JIT 实际上还是将源代码编译成机器码交由 cpu 执行.</description></item><item><title>对协程的一点认识</title><link>/posts/coroutine/</link><pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate><guid>/posts/coroutine/</guid><description>协程的调度 我们知道线程是 CPU 的基本调度单元，线程调度靠的是时钟中断.
协程是执行于线程之内的更细粒度的执行单元，他的调度无法依赖时钟中断，而是要靠一个用户态的调度器，这个调度器可以是抢占式或非抢占式，抢占式调度器需要语言的运行时支持，据我所知只有 erlang 实现了协程的抢占式调度。大部分的协程实现都是非抢占式调度，非抢占式调度实际上是依靠协程之间相互让权 (yield) 来得到执行。
在非抢占式协程下，不存在协程同步问题。而在抢占式协程下则语言我们也考虑数据竞争，协程同步问题。
协程的好处 协程的一个典型应用是用在生产者 - 消费者问题中. 我们知道生产者 - 消费者问题也可以用多线程解决, 生产者线程和消费者线程共享一个上了锁的消息队列, 靠内核调度这两个线程执行来完成生产和消费过程, 然而这里有两个不足之处:
靠内核调度线程, 存在线程切换开销 消息队列加锁, 存在锁竞争和线程同步问题 内核调度线程的时机不确定, 如果在调度消费者时队列中没有消息, 消费者只能什么也不干就退出, 白白浪费了一次调度而如果用协程解决的话, 就不存在上述问题. 首先生产者和消费者协程位于统一线程里, 不存在线程切换的开销; 其次由于是单线程, 无需加锁, 也就不存在锁竞争问题; 最后由于协程之间的执行是靠主动让权 (yield), 我们可以在实现的时候仅当队列不空时才让权给消费者, 同理消费者仅当队列不满时才让权给生产者.
另外使用协程还有一个好处就是能够以看似同步的方式写异步的代码.
协程实现 要实现协程就需要自己在线程中维护第二层栈空间 (第一层是线程自己的栈空间), 因为线程的切换内核会为我们将当前上下文 (主要是各个寄存器的值) 保存在线程栈空间中, 现在由于线程需要自己调度协程, 所以线程需要为每个协程维护栈空间, 好在协程切换时保存协程的上下文.
这里需要线程能够获去到当前执行上下文, 很多操作系统内核会提供相应的系统调用, 实现方式其实也很简单就是写一段内嵌的汇编获取各个寄存器的值.
在 C/C++ 中, setjmp/longjmp 帮我们完成了这个任务. 关于其 setjmp/longjmp 的实现原理, 这里有篇 Google 排名第一的文章 讲的很清楚. C/C++ 中实现协程当然也可以不借助 setjmp/longjmp 而自己去实现上下文的获取和维护, Google 可以搜到不少.</description></item><item><title>C++ 的左右值与左右值引用</title><link>/posts/c-plus-plus-reference/</link><pubDate>Sun, 29 Apr 2018 00:00:00 +0000</pubDate><guid>/posts/c-plus-plus-reference/</guid><description>左值与右值 C++ 中左值和右值的概念来源于 C, 在 C 中左值和右值的区别很简单, 能出现在赋值号左侧的就是左值, 否则就是右值. 比如变量是左值, 字面常量或者 const 定义的常量是右值.
然而在 C++ 中, 左值和右值的区别就不再是那么简单了, 甚至和 C 还会有冲突, 比如在 C 中 const 定义的常量对象是右值, 而在 C++ 中却是左值.
实际上在 C++ 中左值和右值的情况非常复杂, 有时区分他们也是非常困难的. Scott Meyers 大师在其 Effective Modern C++ 一书所说的不失为一个好方法, 在理解这句话之前, 我们一定要有一个意识, 就是左值和右值是表达式的属性, 代表着表达式的运算结果是左值还是右值.
A useful heuristic to determine whether an expression is an lvalue is to ask if you can take its address. If you can, it typically is. If you can’t, it’s usually an rvalue.</description></item><item><title>如何在应用层控制最大客户端连接</title><link>/posts/controlling-client-connections/</link><pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate><guid>/posts/controlling-client-connections/</guid><description>当有客户端连接, 而程序中没有去处理时, select 就回持续不断的返回这个文件描述符可写, 例如, 下面是我以前写的一段有 bug 的程序:
int csocks[MAX_CONNECTION]; memset(csocks, -1, MAX_CONNECTION * sizeof(int)); FD_SET(sock, &amp;amp;rset); while(1) { if (select(FD_SETSIZE, &amp;amp;rset, NULL, NULL, NULL) &amp;lt;= 0) { return ; } if (FD_ISSET(sock, &amp;amp;rset)) { // looking for an unused socket for (int i = 0 ; i &amp;lt; MAX_CONNECTION; ++i) { if((-1 == csocks[i]) &amp;amp;&amp;amp; (-1 != (csocks[i] = accept(sock, NULL, NULL)))) break; } } } 这段程序里, sock 是一个侦听套接字, 负责侦听客户端的连接, 一有连接就会去调用 accept 来接受客户端的连接 &amp;mdash; 当然, 这是有条件的, 那就是能够接收的最大的客户端数量是 MAX_CONNECTION, 由上面的程序里可以看到, 当连接的客户端的数量已经超过了 MAX_CONNECTION 时, 将不会再接受任何连接.</description></item><item><title>C 语言宏的展开与字符串化宏和符号连接宏</title><link>/posts/c-macro/</link><pubDate>Tue, 20 Feb 2018 00:00:00 +0000</pubDate><guid>/posts/c-macro/</guid><description>C 语言由于没什么高级的特性, 所以现有的特性被玩的各种精. 宏展开就是很值得品味的部分.
递归展开问题 宏定义语句是这样的:
#define identifier token-sequence
在具体的宏展开过程中, 遇到标识符时, 此标识符会整个的被使用 token-sequence 展开, 如果 token-sequence 中还包含有其他的被定义的宏标识符, 也都会相应的被展开. 但是显然, 已经展开过的标识符如果再次出现, 则维持原样不变, 不会再次展开, 否则就递归个没完了.
比如说有如下代码段:
#define x y #define y x x 对其执行 gcc -E 预处理时得到的结果是 x, 这里发生了两步替换, 首先 x 被展开成 y, 然后因为 y 也被定义为宏, y 又展开成 x. 注意此时, 由于 x 这个标识符已经展开过, 这里是第二次出现, 所以不会被再次展开成 y. 不然就没完没了了.
这部分可以参见 K&amp;amp;R C, A.12 中有这么一段话:
In both kinds of macro, the replacement token sequence is repeatedly rescanned for more defined identifiers.</description></item><item><title>深入解读同步/异步 IO 编程模型</title><link>/posts/io-programming/</link><pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate><guid>/posts/io-programming/</guid><description>所谓 &amp;ldquo;同步&amp;rdquo; 和 &amp;ldquo;异步&amp;rdquo; 是从调用者的角度来说的. 如果调用者不得不等待 IO 完成才能执行后续的工作, 那就是同步; 否则, 就是异步. 这是我对 &amp;ldquo;同步&amp;rdquo; 和 &amp;ldquo;异步&amp;rdquo; 的定义, 这个定义清晰精炼, 巧妙的帮我们把 &amp;ldquo;理解什么叫做异步&amp;rdquo; 这项工作简化成了 &amp;ldquo;理解什么叫做 IO 完成&amp;rdquo;.
在 *nix 系统中, IO 操作分为两个阶段. 第一阶段是从用户空间发起请求到数据真正就绪的等待阶段, 第二阶段是数据就绪后从用户空间或者内核空间拷贝给对方的数据拷贝阶段. 只有这两个阶段都完成了, 才叫做 &amp;ldquo;IO 完成&amp;rdquo;.
如果看过圣书 Unix Network Programming Volume 1 , 就知道 Richard 介绍了 5 种 IO 模型, 下面我们按照上面的定义给这 5 中模型分个类.
Blocking IO 这个模型是最简单的, 程序流调用 read/writei, 如果运气好正好有数据, 就进行 IO 第二阶段, 否则就卡在第一阶段等数据就绪. 当第二阶段结束 read/write 返回后, 继续执行后面的程序.
/* processing work A */ read(fd, buf, size); /* blocked here */ /* continue processing work B */ 显然这个模型是同步的, 程序流必须等 IO 两个阶段都完成了, 才能得以执行后续的工作.</description></item></channel></rss>