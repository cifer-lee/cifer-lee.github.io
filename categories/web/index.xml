<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Web on</title><link>cifer76.github.io/categories/web/</link><description>Recent content in Web on</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Wed, 13 Feb 2019 00:00:00 +0000</lastBuildDate><atom:link href="cifer76.github.io/categories/web/index.xml" rel="self" type="application/rss+xml"/><item><title>浏览器追踪技术与防范</title><link>cifer76.github.io/posts/browser-tracking/</link><pubDate>Wed, 13 Feb 2019 00:00:00 +0000</pubDate><guid>cifer76.github.io/posts/browser-tracking/</guid><description>Cookie 这里说的就是我们通常所熟知的 cookie，很多第三方公司就是借助这种 cookie 实现追踪的。比如网站 A，B 都使用了 DoubleClick 的 js 脚本，DoubleClick 的脚本在用户访问网站 A 时被加载并埋下 cookie，下次用户访问网站 B 时这个信息会上报回给 DoubleClick。这种方式实现起来简单，防范也简单，定期清理 cookie 就能定期的中断跟踪，或者我们也可以直接禁止第三方 cookie 就好了，不过这样一来一些非跟踪的第三方服务比如 google analytics/adsense 也会被误杀。
Supercookie Supercookie 应该是一个统称，不同于普通的 cookie，supercookie 通过各种奇技淫巧达到让用户难以清除甚至无法清除的目地。比如利用 flash 插件存储 cookie 数据，这样一来 cookie 数据就存放于 flash 插件的存储区，而浏览器一般是没有提供插件数据清理功能的，这就阻拦了大部分用户清理 cookie；另外还有一种方式叫做 Image hack，它利用了浏览器默认会缓存图片的行为，给你生成一张 100 像素的每个像素的颜色对你也是固定的小图片，以此来标记你，当浏览器下次发出请求时，一段简单的 js 代码就能够读出缓存中这张图片的像素颜色特征。
这两种方式可算是奇淫，但仍然是把特征信息存在用户电脑上，只要用户想，还是能够清除他们的。然而下面这第三种方式就真的无法清除了。
第三种方式是直接由 ISP 厂商参与，在中途给你插入 cookie 信息。具体来说就是 ISP 厂商分析你的流量，发现是 HTTP 请求，就使用你的网络接入信息给你生成 cookie 信息。这一勾当最早是由美国 Verizon 电信公司实践的，Verizon 为了更好的服务自己的那些广告主们，用这种方式跟踪用户。虽然这种方式使得我们无法清除 cookie，但因为这种方式需要 ISP 分析发现 HTTP 流量，所以只要我们尽可能的只访问 HTTPS 服务（HTTPS Everywhere 插件能够帮助我们尽可能多的走 HTTPS 链路），还是能够有效防止被通过这种方式跟踪的。</description></item><item><title>通俗地解释 CGI, FastCGI, php-fpm 之间的关系</title><link>cifer76.github.io/posts/cgi-fastcgi-php-fpm/</link><pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate><guid>cifer76.github.io/posts/cgi-fastcgi-php-fpm/</guid><description>这要了解一点万维网 (WWW) 的历史, 才能更好地了解个中关系.
早期的网站基本都是静态的, 那时候的 web server 几乎所有工作就是给访问者提供静态资源, 网站与访问者之间缺乏交互. 后来随着 WWW 的发展网站变得交互性强了起来, 交互性强了也意味着 web server 端的业务逻辑复杂了起来, 不再是简单地解析 url, 定位并返回用户请求的资源, 而是要处理很多用户请求的动态资源以及许多复杂的业务, 这些工作都交给 web server 来做是不现实的, 因为单纯作为 web server 是不知道也不应该关注业务的.
于是 CGI 出现了, 它使得 web server 可以把复杂的业务逻辑交给 cgi 脚本程序来做, CGI 协议定义了 web server 与 cgi 程序之间通信的 context, web server 一收到动态资源的请求就 fork 一个子进程调用 cgi 程序处理这个请求, 同时将和此请求相关的 context 传给 cgi 程序, 像是 path_info, script path, request method, remote ip 等等&amp;hellip;
但是显然每次来个请求 web server 就去 fork 子进程是很低效的, 在网站访问量逐渐增大时网站性能问题日益凸显.</description></item></channel></rss>